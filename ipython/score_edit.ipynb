{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score an edit!\n",
    "In this notebook, we'll look at the the facilities that revscoring gives you for loading in a model and scoring some edits with it.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the scorer model\n",
    "In this step, we'll load a scorer model file from the disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Information:\n",
      "\t - type: GradientBoosting\n",
      "\t - version: 0.4.0\n",
      "\t - params: {'init': None, 'verbose': 0, 'loss': 'deviance', 'labels': [True, False], 'label_weights': OrderedDict([(True, 10)]), 'criterion': 'friedman_mse', 'learning_rate': 0.01, 'min_samples_split': 2, 'population_rates': None, 'random_state': None, 'subsample': 1.0, 'warm_start': False, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'min_weight_fraction_leaf': 0.0, 'max_features': 'log2', 'center': True, 'max_leaf_nodes': None, 'scale': True, 'min_impurity_split': None, 'presort': 'auto', 'max_depth': 7, 'n_estimators': 700, 'multilabel': False}\n",
      "\tEnvironment:\n",
      "\t - revscoring_version: '2.2.2'\n",
      "\t - platform: 'Linux-4.9.0-6-amd64-x86_64-with-debian-9.4'\n",
      "\t - machine: 'x86_64'\n",
      "\t - version: '#1 SMP Debian 4.9.82-1+deb9u3 (2018-03-02)'\n",
      "\t - system: 'Linux'\n",
      "\t - processor: ''\n",
      "\t - python_build: ('default', 'Jan 19 2017 14:11:04')\n",
      "\t - python_compiler: 'GCC 6.3.0 20170118'\n",
      "\t - python_branch: ''\n",
      "\t - python_implementation: 'CPython'\n",
      "\t - python_revision: ''\n",
      "\t - python_version: '3.5.3'\n",
      "\t - release: '4.9.0-6-amd64'\n",
      "\t\n",
      "\tStatistics:\n",
      "\tcounts (n=19455):\n",
      "\t\tlabel        n         ~True    ~False\n",
      "\t\t-------  -----  ---  -------  --------\n",
      "\t\tTrue       751  -->      422       329\n",
      "\t\tFalse    18704  -->      731     17973\n",
      "\trates:\n",
      "\t\t              True    False\n",
      "\t\t----------  ------  -------\n",
      "\t\tsample       0.039    0.961\n",
      "\t\tpopulation   0.034    0.966\n",
      "\tmatch_rate (micro=0.913, macro=0.5):\n",
      "\t\t  False    True\n",
      "\t\t-------  ------\n",
      "\t\t  0.943   0.057\n",
      "\tfilter_rate (micro=0.087, macro=0.5):\n",
      "\t\t  False    True\n",
      "\t\t-------  ------\n",
      "\t\t  0.057   0.943\n",
      "\trecall (micro=0.947, macro=0.761):\n",
      "\t\t  False    True\n",
      "\t\t-------  ------\n",
      "\t\t  0.961   0.562\n",
      "\t!recall (micro=0.576, macro=0.761):\n",
      "\t\t  False    True\n",
      "\t\t-------  ------\n",
      "\t\t  0.562   0.961\n",
      "\tprecision (micro=0.962, macro=0.661):\n",
      "\t\t  False    True\n",
      "\t\t-------  ------\n",
      "\t\t  0.984   0.337\n",
      "\t!precision (micro=0.359, macro=0.661):\n",
      "\t\t  False    True\n",
      "\t\t-------  ------\n",
      "\t\t  0.337   0.984\n",
      "\tf1 (micro=0.954, macro=0.697):\n",
      "\t\t  False    True\n",
      "\t\t-------  ------\n",
      "\t\t  0.972   0.421\n",
      "\t!f1 (micro=0.44, macro=0.697):\n",
      "\t\t  False    True\n",
      "\t\t-------  ------\n",
      "\t\t  0.421   0.972\n",
      "\taccuracy (micro=0.947, macro=0.947):\n",
      "\t\t  False    True\n",
      "\t\t-------  ------\n",
      "\t\t  0.947   0.947\n",
      "\tfpr (micro=0.424, macro=0.239):\n",
      "\t\t  False    True\n",
      "\t\t-------  ------\n",
      "\t\t  0.438   0.039\n",
      "\troc_auc (micro=0.924, macro=0.924):\n",
      "\t\t  False    True\n",
      "\t\t-------  ------\n",
      "\t\t  0.924   0.924\n",
      "\tpr_auc (micro=0.978, macro=0.722):\n",
      "\t\t  False    True\n",
      "\t\t-------  ------\n",
      "\t\t  0.997   0.447\n",
      "\t\n",
      "\t - score_schema: {'properties': {'prediction': {'type': 'bool', 'description': 'The most likely label predicted by the estimator'}, 'probability': {'properties': {'false': 'number', 'true': 'number'}, 'type': 'object', 'description': 'A mapping of probabilities onto each of the potential output labels'}}, 'type': 'object', 'title': 'Scikit learn-based classifier score with probability'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from revscoring import Model\n",
    "sm = Model.load(open(\"../models/enwiki.damaging.gradient_boosting.model\"), env_check=False)\n",
    "print(sm.info.format())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepare an extractor\n",
    "We're using a model that was trained on English Wikipedia.  We'll build an extractor to pull features from English Wikipedia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mwapi\n",
    "from revscoring.extractors import api\n",
    "\n",
    "extractor = api.Extractor(mwapi.Session(\"https://en.wikipedia.org\", user_agent=\"Score edit demo in editquality\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Extract features and score an edit\n",
    "Now, we'll use the extractor to extract features for a revision ID and then ask the scorer model to generate a prediction based on those features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<feature.revision.page.is_articleish>, True),\n",
       " (<feature.revision.page.is_mainspace>, True),\n",
       " (<feature.revision.page.is_draftspace>, False),\n",
       " (<feature.log((wikitext.revision.parent.chars + 1))>, 10.618934240590841),\n",
       " (<feature.log((len(<datasource.tokenized(datasource.revision.parent.text)>) + 1))>,\n",
       "  9.45234493093131),\n",
       " (<feature.log((len(<datasource.wikitext.revision.parent.words>) + 1))>,\n",
       "  8.372860820526318),\n",
       " (<feature.log((len(<datasource.wikitext.revision.parent.uppercase_words>) + 1))>,\n",
       "  5.976350909297934),\n",
       " (<feature.log((wikitext.revision.parent.headings + 1))>, 3.091042453358316),\n",
       " (<feature.log((wikitext.revision.parent.wikilinks + 1))>, 5.846438775057725),\n",
       " (<feature.log((wikitext.revision.parent.external_links + 1))>,\n",
       "  4.442651256490317)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_to_score = 71076450\n",
    "feature_values = list(extractor.extract(rev_to_score, sm.features))\n",
    "list(zip(sm.features, feature_values))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': True,\n",
       " 'probability': {False: 0.23860839638483888, True: 0.7613916036151611}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.score(feature_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
