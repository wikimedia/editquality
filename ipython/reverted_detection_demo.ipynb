{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic damage detection in Wikipedia\n",
    "This notebook demonstrates the basic contruction of a vandalism classification system using the [revscoring](http://pythonhosted.org/revscoring/) library that we have developed specifically for classification models of MediaWiki stuff.\n",
    "\n",
    "The basic process that we'll follow is this:\n",
    "\n",
    "1. Gather example of human judgement applied to Wikipedia edits.  In this case, we'll take advantage of [reverts](https://meta.wikimedia.org/wiki/Research:Revert).  \n",
    "2. Split the data into a training and testing set\n",
    "3. Training the machine learning model\n",
    "4. Testing the machine learning model\n",
    "\n",
    "And then we'll have some fun applying the model to some edits using RCStream.  The following diagram gives a good sense for the whole process of training and evaluating a model.\n",
    "\n",
    "<img style=\"text-align: center;\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/09/Supervised_machine_learning_in_a_nutshell.svg/640px-Supervised_machine_learning_in_a_nutshell.svg.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Getting labeled observations\n",
    "<img style=\"float: right; margin: 1ex;\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/0f/Machine_learning_nutshell_--_Gather_labeled_observations.svg/300px-Machine_learning_nutshell_--_Gather_labeled_observations.svg.png\" />\n",
    "\n",
    "Regretfully, running SQL queries isn't something we can do directly from the notebook *yet*.  So, we'll use [Quarry](https://quarry.wmflabs.org) to generate a nice random sample of edits.  20,000 observations should do just fine.  Here's the query I want to run:\n",
    "\n",
    "```SQL\n",
    "USE enwiki_p;\n",
    "SELECT rev_id \n",
    "FROM revision \n",
    "WHERE rev_timestamp BETWEEN \"20150201\" AND \"20160201\" \n",
    "ORDER BY RAND() \n",
    "LIMIT 20000;\n",
    "```\n",
    "\n",
    "See http://quarry.wmflabs.org/query/7530.  By clicking around the UI, I can see that this URL will download my tab-separated file: http://quarry.wmflabs.org/run/65415/output/0/tsv?download=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Magical ipython notebook stuff puts the result of this command into a variable\n",
    "revids_f = !wget http://quarry.wmflabs.org/run/65415/output/0/tsv\\?download=true -qO- \n",
    "\n",
    "revids = [int(line) for line in revids_f[1:]]\n",
    "len(revids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK.  Now that we have a set of revisions, we need to label them.  In this case, we're going to label them as reverted/not.  We want to exclude a few different types of reverts -- e.g. when a user reverts themself or when an edit is reverted back to by someone else.  For this, we'll use the [mwreverts](https://pythonhosted.org/mwreverts) and [mwapi](https://pythonhosted.org/mwapi) libraries.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...............r...."
     ]
    }
   ],
   "source": [
    "import sys, traceback\n",
    "import mwreverts.api\n",
    "import mwapi\n",
    "\n",
    "# We'll use the mwreverts API check.  In order to do that, we need an API session\n",
    "session = mwapi.Session(\"https://en.wikipedia.org\", \n",
    "                        user_agent=\"Revert detection demo <ahalfaker@wikimedia.org>\")\n",
    "\n",
    "# For each revision, find out if it was \"reverted\" and label it so.\n",
    "rev_reverteds = []\n",
    "for rev_id in revids[:20]:  # NOTE: Limiting to the first 20!!!!\n",
    "    try:\n",
    "        _, reverted, reverted_to = mwreverts.api.check(\n",
    "            session, rev_id, radius=5,  # most reverts within 5 edits\n",
    "            window=48*60*60,  # 2 days\n",
    "            rvprop={'user', 'ids'})  # Some properties we'll make use of\n",
    "    except (RuntimeError, KeyError) as e:\n",
    "        sys.stderr.write(str(e))\n",
    "        continue\n",
    "    \n",
    "    if reverted is not None:\n",
    "        reverted_doc = [r for r in reverted.reverteds\n",
    "                        if r['revid'] == rev_id][0]\n",
    "\n",
    "        if 'user' not in reverted_doc or 'user' not in reverted.reverting:\n",
    "            continue\n",
    "\n",
    "        # self-reverts\n",
    "        self_revert = \\\n",
    "            reverted_doc['user'] == reverted.reverting['user']\n",
    "        \n",
    "        # revisions that are reverted back to by others\n",
    "        reverted_back_to = \\\n",
    "            reverted_to is not None and \\\n",
    "            'user' in reverted_to.reverting and \\\n",
    "            reverted_doc['user'] != \\\n",
    "            reverted_to.reverting['user']\n",
    "        \n",
    "        # If we are reverted, not by self or reverted back to by someone else, \n",
    "        # then, let's assume it was damaging.\n",
    "        damaging_reverted = not (self_revert or reverted_back_to)\n",
    "    else:\n",
    "        damaging_reverted = False\n",
    "\n",
    "    rev_reverteds.append((rev_id, damaging_reverted))\n",
    "    sys.stderr.write(\"r\" if damaging_reverted else \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eeek!  This takes too long.  You get the idea.  So, I uploaded dataset that has already been labeled here @ `../datasets/demo/enwiki.rev_reverted.20k_2015.tsv.bz2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19868"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_reverteds_f = !bzcat ../datasets/demo/enwiki.rev_reverted.20k_2015.tsv.bz2\n",
    "rev_reverteds = [line.strip().split(\"\\t\") for line in rev_reverteds_f[1:]]\n",
    "rev_reverteds = [(int(rev_id), reverted == \"True\") for rev_id, reverted in rev_reverteds]\n",
    "len(rev_reverteds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK.  It looks like we got an error when trying to extract the reverted status of ~132 edits, which is an acceptable loss.  Now just to make sure we haven't gone crazy, let's check some of the reverted edits:\n",
    "\n",
    "* https://en.wikipedia.org/wiki/?diff=695071713 (section blanking)\n",
    "* https://en.wikipedia.org/wiki/?diff=667375206 (unexplained addition of nonsense)\n",
    "* https://en.wikipedia.org/wiki/?diff=670204366 (vandalism \"I don't know\")\n",
    "* https://en.wikipedia.org/wiki/?diff=680329354 (adds non-existent category)\n",
    "* https://en.wikipedia.org/wiki/?diff=668682186 (test edit -- removes punctuation)\n",
    "* https://en.wikipedia.org/wiki/?diff=666882037 (adds spamlink)\n",
    "* https://en.wikipedia.org/wiki/?diff=663302354 (adds nonsense special char)\n",
    "* https://en.wikipedia.org/wiki/?diff=675803278 (unconstructive link changes)\n",
    "* https://en.wikipedia.org/wiki/?diff=680203994 (vandalism -- \"Pepe meme\")\n",
    "* https://en.wikipedia.org/wiki/?diff=656734057 (\"JELENAS BOOTY UNDSO\")\n",
    "\n",
    "OK.  Looks like we are doing pretty good. :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Split the data into a training and testing set\n",
    "<img style=\"float: right; margin: 1ex;\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Machine_learning_nutshell_--_Split_into_train-test_set.svg/320px-Machine_learning_nutshell_--_Split_into_train-test_set.svg.png\" />\n",
    "Before we move on with training, it's important that we hold back some of the data for testing later.  If we train on the same data we'll test with, we risk [overfitting](https://en.wikipedia.org/wiki/Overfitting) and not noticing!\n",
    "\n",
    "In this section, we'll both split the training and testing set *and* gather prective features for each of the labeled observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: 15000\n",
      "testing: 4868\n"
     ]
    }
   ],
   "source": [
    "train_set = rev_reverteds[:15000]\n",
    "test_set = rev_reverteds[15000:]\n",
    "print(\"training:\", len(train_set))\n",
    "print(\"testing:\", len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK.  In order to train the machine learning model, we'll need to give it a source of signal.  This is where \"features\" come into play.  A feature represents a simple numerical statistic that we can extract from our observations that we think will be *predictive* of our outcome.  Luckily, `revscoring` provides a whole suite of features that work well for damage detection.  In this case, we'll be looking at features of the edit diff.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from revscoring.features import wikitext, revision_oriented, temporal\n",
    "from revscoring.languages import english\n",
    "\n",
    "features = [\n",
    "    # Catches long key mashes like kkkkkkkkkkkk\n",
    "    wikitext.revision.diff.longest_repeated_char_added,\n",
    "    # Measures the size of the change in added words\n",
    "    wikitext.revision.diff.words_added,\n",
    "    # Measures the size of the change in removed words\n",
    "    wikitext.revision.diff.words_removed,\n",
    "    # Measures the proportional change in \"badwords\"\n",
    "    english.badwords.revision.diff.match_prop_delta_sum,\n",
    "    # Measures the proportional change in \"informals\"\n",
    "    english.informals.revision.diff.match_prop_delta_sum,\n",
    "    # Measures the proportional change meaningful words\n",
    "    english.stopwords.revision.diff.non_stopword_prop_delta_sum,\n",
    "    # Is the user anonymous\n",
    "    revision_oriented.revision.user.is_anon,\n",
    "    # Is the user a bot or a sysop\n",
    "    revision_oriented.revision.user.in_group({'bot', 'sysop'}),\n",
    "    # How long ago did the user register?\n",
    "    temporal.revision.user.seconds_since_registration\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll need to turn to `revscoring`s feature extractor to help us get us feature values for each revision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/wiki/?diff=695071713\n",
      "[1, 0.0, 11137.0, -1.0, -2.5476190476190474, -1475.2742410317746, True, False, 0]\n",
      "https://en.wikipedia.org/wiki/?diff=667375206\n",
      "[1, 1.0, 1.0, 0.0, 0.0, 0.33333333333333337, False, False, 9844289]\n"
     ]
    }
   ],
   "source": [
    "from revscoring.extractors import api\n",
    "api_extractor = api.Extractor(session)\n",
    "\n",
    "revisions = [695071713, 667375206]\n",
    "for rev_id in revisions:\n",
    "    print(\"https://en.wikipedia.org/wiki/?diff={0}\".format(rev_id))\n",
    "    print(list(api_extractor.extract(rev_id, features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...................."
     ]
    }
   ],
   "source": [
    "# Now for the whole set!\n",
    "training_features_reverted = []\n",
    "for rev_id, reverted in train_set[:20]:\n",
    "    try:\n",
    "        feature_values = list(api_extractor.extract(rev_id, features))\n",
    "        observation = {\"rev_id\": rev_id, \"cache\": feature_values, \"reverted\": reverted}\n",
    "    except RuntimeError as e:\n",
    "        sys.stderr.write(str(e))\n",
    "        continue\n",
    "    \n",
    "    sys.stderr.write(\".\")\n",
    "    training_features_reverted.append(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to regenerate the observations file.\n",
    "#import bz2\n",
    "#from revscoring.utilities.util import dump_observation\n",
    "#\n",
    "#f = bz2.open(\"../datasets/demo/enwiki.features_reverted.training.20k_2015.json.bz2\", \"wt\")\n",
    "#for observation in training_features_reverted:\n",
    "#    dump_observation(observation, f)\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eeek!  Again this takes too long, so again, I uploaded a dataset with features already extracted @ `../datasets/demo/enwiki.features_reverted.training.20k_2015.tsv.bz2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if at one point the json.bz2 is uploaded again or if you recreated it from the step above.\n",
    "\n",
    "# from revscoring.utilities.util import read_observations\n",
    "# training_features_reverted_f = !bzcat ../datasets/demo/enwiki.features_reverted.training.20k_2015.json.bz2\n",
    "# training_features_reverted = list(read_observations(training_features_reverted_f))\n",
    "# training_unpacked = [(o[\"cache\"], o[\"reverted\"]) for o in training_features_reverted]\n",
    "# len(training_unpacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14979"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comment if you uncommented the section above\n",
    "from revscoring.utilities.util import unpack_observations_tsv\n",
    "\n",
    "training_features_reverted_f = !bzcat ../datasets/demo/enwiki.features_reverted.training.20k_2015.tsv.bz2\n",
    "training_unpacked = unpack_observations_tsv(training_features_reverted_f, features)\n",
    "len(training_unpacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Training the model\n",
    "<img style=\"float: right; margin: 1ex;\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/7/7a/Machine_learning_nutshell_--_Train_a_machine_learning_model.svg/320px-Machine_learning_nutshell_--_Train_a_machine_learning_model.svg.png\" />\n",
    "\n",
    "Now that we have a set of features extracted for our training set, it's time to train a model.  `revscoring` provides a set of different classifier algorithms.  From past experience, I know a [gradient boosting](https://en.wikipedia.org/wiki/Gradient_boosting) classifier works well, so we'll use that.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seconds_elapsed': 5.3657426834106445}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from revscoring.scoring.models import GradientBoosting\n",
    "is_reverted = GradientBoosting(features, labels=[True, False], version=\"live demo!\", \n",
    "                               learning_rate=0.01, max_features=\"log2\", \n",
    "                               n_estimators=700, max_depth=5,\n",
    "                               population_rates={False: 0.5, True: 0.5}, scale=True, center=True)\n",
    "    \n",
    "is_reverted.train(training_unpacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a trained model that we can play around with.  Let's try a few edits from our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True https://en.wikipedia.org/wiki/?diff=699665317 False 0.3\n",
      "True https://en.wikipedia.org/wiki/?diff=683832871 False 0.26\n",
      "True https://en.wikipedia.org/wiki/?diff=653913156 False 0.2\n",
      "True https://en.wikipedia.org/wiki/?diff=654545786 True 0.56\n",
      "True https://en.wikipedia.org/wiki/?diff=670608733 False 0.2\n",
      "True https://en.wikipedia.org/wiki/?diff=689399141 False 0.14\n",
      "True https://en.wikipedia.org/wiki/?diff=662365029 True 0.55\n",
      "True https://en.wikipedia.org/wiki/?diff=656782076 False 0.31\n",
      "True https://en.wikipedia.org/wiki/?diff=698954388 False 0.36\n",
      "True https://en.wikipedia.org/wiki/?diff=645603577 False 0.17\n",
      "False https://en.wikipedia.org/wiki/?diff=687073859 False 0.04\n",
      "False https://en.wikipedia.org/wiki/?diff=665341163 False 0.01\n",
      "False https://en.wikipedia.org/wiki/?diff=654524549 False 0.02\n",
      "False https://en.wikipedia.org/wiki/?diff=682425664 False 0.01\n",
      "False https://en.wikipedia.org/wiki/?diff=674780271 False 0.02\n",
      "False https://en.wikipedia.org/wiki/?diff=684793059 False 0.01\n",
      "False https://en.wikipedia.org/wiki/?diff=655583788 False 0.15\n",
      "RevisionNotFound: Could not find revision ({revision}:700003789)\n",
      "False https://en.wikipedia.org/wiki/?diff=659306547 False 0.01\n",
      "False https://en.wikipedia.org/wiki/?diff=662149200 False 0.01\n"
     ]
    }
   ],
   "source": [
    "from revscoring.errors import RevisionNotFound\n",
    "reverted_obs = [rev_id for rev_id, reverted in test_set if reverted]\n",
    "non_reverted_obs = [rev_id for rev_id, reverted in test_set if not reverted]\n",
    "\n",
    "for rev_id in reverted_obs[:10]:\n",
    "    try:\n",
    "        feature_values = list(api_extractor.extract(rev_id, features))\n",
    "        score = is_reverted.score(feature_values)\n",
    "        print(True, \"https://en.wikipedia.org/wiki/?diff=\" + str(rev_id), \n",
    "            score['prediction'], round(score['probability'][True], 2))\n",
    "    except RevisionNotFound as err:\n",
    "        print(err)\n",
    "\n",
    "\n",
    "for rev_id in non_reverted_obs[:10]:\n",
    "    try:\n",
    "        feature_values = list(api_extractor.extract(rev_id, features))\n",
    "        score = is_reverted.score(feature_values)\n",
    "        print(False, \"https://en.wikipedia.org/wiki/?diff=\" + str(rev_id), \n",
    "            score['prediction'], round(score['probability'][True], 2))\n",
    "    except RevisionNotFound as err:\n",
    "        print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Testing the model\n",
    "So, the above analysis can help give us a sense for whether the model is working or not, but it's hard to standardize between models.  So, we can apply some metrics that are specially crafted for machine learning models.  \n",
    "\n",
    "<center>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/49/Machine_learning_nutshell_--_Test_the_machine_learning_model.svg/640px-Machine_learning_nutshell_--_Test_the_machine_learning_model.svg.png\" />\n",
    "</center>\n",
    "\n",
    "But first, I'll need to load the pre-generated feature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Uncomment if at one point the json.bz2 is uploaded again\n",
    "\n",
    "# testing_features_reverted_f = !bzcat ../datasets/demo/enwiki.features_reverted.testing.20k_2015.json.bz2\n",
    "# testing_features_reverted = list(read_observations(testing_features_reverted_f))\n",
    "# testing_unpacked = [(o[\"cache\"], o[\"reverted\"]) for o in testing_features_reverted]\n",
    "# len(testing_unpacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4862"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comment if you uncommented the section above\n",
    "testing_features_reverted_f = !bzcat ../datasets/demo/enwiki.features_reverted.testing.20k_2015.tsv.bz2\n",
    "testing_unpacked = unpack_observations_tsv(testing_features_reverted_f, features)\n",
    "len(testing_unpacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision) -- The proportion of correct predictions\n",
    "* [Precision](https://en.wikipedia.org/wiki/Precision_and_recall) -- The proportion of correct positive predictions\n",
    "* [Recall](https://en.wikipedia.org/wiki/Precision_and_recall) -- The proportion of positive examples predicted as positive\n",
    "* Filter rate at 90% recall -- The proportion of observations that can be ignored while still catching 90% of \"reverted\" edits.  \n",
    "\n",
    "We'll use `revscoring` statistics to measure these against the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Information:\n",
      "\t - type: GradientBoosting\n",
      "\t - version: live demo!\n",
      "\t - params: {'scale': True, 'center': True, 'labels': [True, False], 'multilabel': False, 'population_rates': None, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 700, 'n_iter_no_change': None, 'presort': 'deprecated', 'random_state': None, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False, 'label_weights': None}\n",
      "\tEnvironment:\n",
      "\t - revscoring_version: '2.11.1'\n",
      "\t - platform: 'Darwin-21.2.0-x86_64-i386-64bit'\n",
      "\t - machine: 'x86_64'\n",
      "\t - version: 'Darwin Kernel Version 21.2.0: Sun Nov 28 20:28:41 PST 2021; root:xnu-8019.61.5~1/RELEASE_ARM64_T6000'\n",
      "\t - system: 'Darwin'\n",
      "\t - processor: 'i386'\n",
      "\t - python_build: ('default', 'Oct 26 2021 05:57:50')\n",
      "\t - python_compiler: 'Clang 11.1.0 '\n",
      "\t - python_branch: ''\n",
      "\t - python_implementation: 'CPython'\n",
      "\t - python_revision: ''\n",
      "\t - python_version: '3.7.12'\n",
      "\t - release: '21.2.0'\n",
      "\t\n",
      "\tStatistics:\n",
      "\tcounts (n=4862):\n",
      "\t\tlabel       n         ~True    ~False\n",
      "\t\t-------  ----  ---  -------  --------\n",
      "\t\tTrue      266  -->       27       239\n",
      "\t\tFalse    4596  -->       12      4584\n",
      "\trates:\n",
      "\t\t              True    False\n",
      "\t\t----------  ------  -------\n",
      "\t\tsample       0.055    0.945\n",
      "\t\tpopulation   0.5      0.5\n",
      "\tmatch_rate (micro=0.5, macro=0.5):\n",
      "\t\t  True    False\n",
      "\t\t------  -------\n",
      "\t\t 0.052    0.948\n",
      "\tfilter_rate (micro=0.5, macro=0.5):\n",
      "\t\t  True    False\n",
      "\t\t------  -------\n",
      "\t\t 0.948    0.052\n",
      "\trecall (micro=0.549, macro=0.549):\n",
      "\t\t  True    False\n",
      "\t\t------  -------\n",
      "\t\t 0.102    0.997\n",
      "\t!recall (micro=0.549, macro=0.549):\n",
      "\t\t  True    False\n",
      "\t\t------  -------\n",
      "\t\t 0.997    0.102\n",
      "\tprecision (micro=0.751, macro=0.751):\n",
      "\t\t  True    False\n",
      "\t\t------  -------\n",
      "\t\t 0.975    0.526\n",
      "\t!precision (micro=0.751, macro=0.751):\n",
      "\t\t  True    False\n",
      "\t\t------  -------\n",
      "\t\t 0.526    0.975\n",
      "\tf1 (micro=0.436, macro=0.436):\n",
      "\t\t  True    False\n",
      "\t\t------  -------\n",
      "\t\t 0.184    0.689\n",
      "\t!f1 (micro=0.436, macro=0.436):\n",
      "\t\t  True    False\n",
      "\t\t------  -------\n",
      "\t\t 0.689    0.184\n",
      "\taccuracy (micro=0.549, macro=0.549):\n",
      "\t\t  True    False\n",
      "\t\t------  -------\n",
      "\t\t 0.549    0.549\n",
      "\tfpr (micro=0.451, macro=0.451):\n",
      "\t\t  True    False\n",
      "\t\t------  -------\n",
      "\t\t 0.003    0.898\n",
      "\troc_auc (micro=0.87, macro=0.87):\n",
      "\t\t  True    False\n",
      "\t\t------  -------\n",
      "\t\t  0.87     0.87\n",
      "\tpr_auc (micro=0.859, macro=0.859):\n",
      "\t\t  True    False\n",
      "\t\t------  -------\n",
      "\t\t 0.866    0.851\n",
      "\t\n",
      "\t - score_schema: {'title': 'Scikit learn-based classifier score with probability', 'type': 'object', 'properties': {'prediction': {'description': 'The most likely label predicted by the estimator', 'type': 'boolean'}, 'probability': {'description': 'A mapping of probabilities onto each of the potential output labels', 'type': 'object', 'properties': {'true': {'type': 'number'}, 'false': {'type': 'number'}}}}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "is_reverted.test(testing_unpacked)\n",
    "\n",
    "print(is_reverted.info.format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus round!  Let's listen to Wikipedia's vandalism!\n",
    "\n",
    "So we don't have the most powerful damage detection classifier, but then again, we're only including 9 features.  Usually we run with ~60 features and get to much higher levels of fitness.  *but* this model is still useful and it should help us detect the most egregious vandalism in Wikipedia.  In order to listen to Wikipedia, we'll need to connect to [RCStream](https://wikitech.wikimedia.org/wiki/RCStream) -- the same live feed that powers [listen to Wikipedia](http://listen.hatnote.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RevisionNotFound: Could not find revision ({revision}:1572141694)\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=1069516890 0.01\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=1069516892 0.22\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=5668896 0.04\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=626959780 0.01\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=33132253 0.03\n",
      "RevisionNotFound: Could not find revision ({revision}:31461934)\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=119775297 0.02\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=626959779 0.01\n",
      "RevisionNotFound: Could not find revision ({revision}:1572141691)\n",
      "RevisionNotFound: Could not find revision ({revision}:1572141695)\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=2134135 0.09\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=34051955 0.23\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=1069516891 0.06\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=219804989 0.02\n",
      "RevisionNotFound: Could not find revision ({revision}:1572141696)\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=190479185 0.02\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=626959781 0.01\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=1069516894 0.02\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=626959782 0.01\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=1069516893 0.01\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=141404890 0.02\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=61002530 0.04\n",
      "RevisionNotFound: Could not find revision ({revision}:1572141698)\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=69972250 0.02\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=1069516896 0.01\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=125432099 0.02\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=626959783 0.01\n",
      "!!!Please review https://en.wikipedia.org/wiki/?diff=119775298 0.74\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=66185393 0.03\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=56658134 0.03\n",
      "RevisionNotFound: Could not find revision ({revision}:61002529)\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=1069516895 0.01\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=190479186 0.0\n",
      "Good edit https://en.wikipedia.org/wiki/?diff=1069516898 0.34\n",
      "50 revisions were analyzed, breaking.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sseclient import SSEClient as EventSource\n",
    "\n",
    "max_last_changes = 50\n",
    "changes_analyzed = 0\n",
    "url = 'https://stream.wikimedia.org/v2/stream/recentchange'\n",
    "for event in EventSource(url):\n",
    "    if changes_analyzed >= max_last_changes:\n",
    "        print(f\"{max_last_changes} revisions were analyzed, breaking.\")\n",
    "        break\n",
    "    if event.event == 'message':\n",
    "        changes_analyzed = changes_analyzed + 1\n",
    "        try:\n",
    "            change = json.loads(event.data)\n",
    "            if change['type'] not in ('new', 'edit'):\n",
    "                continue\n",
    "        \n",
    "            rev_id = change['revision']['new']\n",
    "            feature_values = list(api_extractor.extract(rev_id, features))\n",
    "            score = is_reverted.score(feature_values)\n",
    "            if score['prediction']:\n",
    "                print(\"!!!Please review\", \"https://en.wikipedia.org/wiki/?diff=\" + str(rev_id), \n",
    "                      round(score['probability'][True], 2), flush=True)\n",
    "            else:\n",
    "                print(\"Good edit\", \"https://en.wikipedia.org/wiki/?diff=\" + str(rev_id),\n",
    "                      round(score['probability'][True], 2), flush=True)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        except RevisionNotFound as err:\n",
    "            print(err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
