{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic damage detection in Wikipedia\n",
    "This notebook demonstrats the basic contruction of a vandalism classification system using [revscoring](http://pythonhosted.org/revscoring/) and [editquality](https://github.org/wiki-ai/editquality). \n",
    "\n",
    "The basic process that we'll follow is this:\n",
    "\n",
    "1. Gather example of human judgement applied to Wikipedia edits.  In this case, we'll take advantage of [reverts](https://meta.wikimedia.org/wiki/Research:Revert).  \n",
    "2. Train a machine learning model on the data.  \n",
    "3. Test the machine learning model against some data we withheld.\n",
    "\n",
    "And then we'll have some fun applying the model to some edits using RCStream.  The following diagram gives a good sense for the whole process.\n",
    "\n",
    "<center><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/09/Supervised_machine_learning_in_a_nutshell.svg/640px-Supervised_machine_learning_in_a_nutshell.svg.png\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Getting labeled observations\n",
    "Regretfully, running SQL queries isn't something we can do directly from the notebook *yet*.  So, we'll use [Quarry](https://quarry.wmflabs.org) to generate a nice random sample of edits.  20,000 observations should do just fine.  Here's the query I want to run:\n",
    "\n",
    "```SQL\n",
    "USE enwiki_p;\n",
    "SELECT rev_id \n",
    "FROM revision \n",
    "WHERE rev_timestamp BETWEEN \"20141001\" AND \"20151001\" \n",
    "ORDER BY RAND() \n",
    "LIMIT 20000;\n",
    "```\n",
    "\n",
    "See http://quarry.wmflabs.org/query/7530.  By clicking around the UI, I can see that this URL will download my tab-separated file: http://quarry.wmflabs.org/run/65415/output/0/tsv?download=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Magical ipython notebook stuff puts the result of this command into a variable\n",
    "revids_f = !wget http://quarry.wmflabs.org/run/65415/output/0/tsv?download=true -qO- \n",
    "\n",
    "revids = [int(line) for line in revids_f[1:]]\n",
    "len(revids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK.  Now that we have a set of revisions, we need to label them.  In this case, we're going to label them as reverted/not.  We want to exclude a few different types of reverts -- e.g. when a user reverts themself or when an edit is reverted back to by someone else.  For this, we'll use the [mwreverts](https://pythonhosted.org/mwreverts) and [mwapi](https://pythonhosted.org/mwapi) libraries.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...............r......."
     ]
    }
   ],
   "source": [
    "import sys, traceback\n",
    "import mwreverts.api\n",
    "import mwapi\n",
    "\n",
    "# We'll use the mwreverts API check.  In order to do that, we need an API session\n",
    "session = mwapi.Session(\"https://en.wikipedia.org\", \n",
    "                        user_agent=\"Revert detection demo <ahalfaker@wikimedia.org>\")\n",
    "\n",
    "# For each revision, find out if it was \"reverted\" and label it so.\n",
    "rev_reverteds = []\n",
    "for rev_id in revids:\n",
    "    try:\n",
    "        _, reverted, reverted_to = mwreverts.api.check(\n",
    "            session, rev_id, radius=5,  # most reverts within 5 edits\n",
    "            window=48*60*60,  # 2 days\n",
    "            rvprop={'user', 'ids'})  # Some properties we'll make use of\n",
    "    except RuntimeError as e:\n",
    "        sys.stderr.write(str(e))\n",
    "        continue\n",
    "    \n",
    "    if reverted is not None:\n",
    "        reverted_doc = [r for r in reverted.reverteds\n",
    "                        if r['revid'] == rev_id][0]\n",
    "\n",
    "        # self-reverts\n",
    "        self_revert = \\\n",
    "            reverted_doc['user'] == reverted.reverting['user']\n",
    "        \n",
    "        # revisions that are reverted back to by others\n",
    "        reverted_back_to = \\\n",
    "            reverted_to is not None and \\\n",
    "            reverted_doc['user'] != \\\n",
    "            reverted_to.reverting['user']\n",
    "        \n",
    "        # If we are reverted, not by self or reverted back to by someone else, \n",
    "        # then, let's assume it was damaging.\n",
    "        damaging_reverted = !(self_revert or reverted_back_to)\n",
    "    else:\n",
    "        damaging_reverted = False\n",
    "\n",
    "    rev_reverteds.append((rev_id, damaging_reverted))\n",
    "    sys.stderr.write(\"r\" if damaging_reverted else \".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eeek!  This takes too long.  You get the idea.  So, I uploaded dataset that has already been labeled here @ `../datasets/demo/enwiki.rev_reverted.20k_2015.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19868"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_reverteds_f = !cat ../datasets/demo/enwiki.rev_reverted.20k_2015.tsv\n",
    "rev_reverteds = [line.strip().split(\"\\t\") for line in rev_reverteds_f[1:]]\n",
    "rev_reverteds = [(int(rev_id), reverted == \"True\") for rev_id, reverted in rev_reverteds]\n",
    "len(rev_reverteds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK.  It looks like we got an error when trying to extract the reverted status of ~132 edits, which is an acceptable loss.  Now just to make sure we haven't gone crazy, let's check some of the reverted edits:\n",
    "\n",
    "* https://en.wikipedia.org/wiki/?diff=695071713 (section blanking)\n",
    "* https://en.wikipedia.org/wiki/?diff=667375206 (unexplained addition of nonsense)\n",
    "* https://en.wikipedia.org/wiki/?diff=670204366 (vandalism \"I don't know\")\n",
    "* https://en.wikipedia.org/wiki/?diff=680329354 (adds non-existent category)\n",
    "* https://en.wikipedia.org/wiki/?diff=668682186 (test edit -- removes punctuation)\n",
    "* https://en.wikipedia.org/wiki/?diff=666882037 (adds spamlink)\n",
    "* https://en.wikipedia.org/wiki/?diff=663302354 (adds nonsense special char)\n",
    "* https://en.wikipedia.org/wiki/?diff=675803278 (unconstructive link changes)\n",
    "* https://en.wikipedia.org/wiki/?diff=680203994 (vandalism -- \"Pepe meme\")\n",
    "* https://en.wikipedia.org/wiki/?diff=656734057 (\"JELENAS BOOTY UNDSO\")\n",
    "\n",
    "OK.  Looks like we are doing pretty good. :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Train the machine learning model on the data\n",
    "Before we move on with training, it's important that we hold back some of the data for testing later.  If we train on the same data we'll test with, we risk [overfitting](https://en.wikipedia.org/wiki/Overfitting) and not noticing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 4868)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = rev_reverteds[:15000]\n",
    "test_set = rev_reverteds[15000:]\n",
    "len(train_set), len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK.  In order to train the machine learning model, we'll need to give it a source of signal.  This is where \"features\" come into play.  A feature represents a simple numerical statistic that we can extract from our observations that we think will be *predictive* of our outcome.  Luckily, `revscoring` provides a whole suite of features that work well for damage detection.  In this case, we'll be looking at features of the edit diff.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from revscoring.features import wikitext\n",
    "from revscoring.languages import english\n",
    "\n",
    "diff_features = [\n",
    "    # Catches long key mashes like kkkkkkkkkkkk\n",
    "    wikitext.revision.diff.longest_repeated_char_added,  \n",
    "    # Measures the size of the change in added words\n",
    "    wikitext.revision.diff.words_added,  \n",
    "    # Measures the size of the change in removed words\n",
    "    wikitext.revision.diff.words_removed,  \n",
    "    # Measures the proportional change in \"badwords\"\n",
    "    english.badwords.revision.diff.match_prop_delta_sum, \n",
    "    # Measures the proportional change in \"informals\"\n",
    "    english.informals.revision.diff.match_prop_delta_sum,  \n",
    "    # Measures the proportional change meaningful words\n",
    "    english.stopwords.revision.diff.non_stopword_prop_delta_sum  \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll need to turn to `revscoring`s feature extractor to help us get us feature values for each revision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "695071713 [1, 0, 10974, -1.0, -2.5476190476190474, -1477.9699604325447]\n",
      "667375206 [1, 1, 1, 0.0, 0.0, 0.33333333333333337]\n"
     ]
    }
   ],
   "source": [
    "from revscoring.extractors import api\n",
    "api_extractor = api.Extractor(session)\n",
    "\n",
    "print(695071713, list(api_extractor.extract(695071713, features)))\n",
    "print(667375206, list(api_extractor.extract(667375206, features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-881ba1056696>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrev_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverted\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mfeature_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi_extractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrev_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/halfak/env/3.4/lib/python3.4/site-packages/revscoring-1.0.0rc2-py3.4.egg/revscoring/dependencies/functions.py\u001b[0m in \u001b[0;36m_solve_many\u001b[1;34m(dependents, context, cache)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdependent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdependents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m         \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_solve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdependent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/halfak/env/3.4/lib/python3.4/site-packages/revscoring-1.0.0rc2-py3.4.egg/revscoring/dependencies/functions.py\u001b[0m in \u001b[0;36m_solve\u001b[1;34m(dependent, context, cache, history)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdependency\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdependencies\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m                 value, cache, history = _solve(dependency, context=context,\n\u001b[1;32m--> 229\u001b[1;33m                                                cache=cache, history=history)\n\u001b[0m\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/halfak/env/3.4/lib/python3.4/site-packages/revscoring-1.0.0rc2-py3.4.egg/revscoring/dependencies/functions.py\u001b[0m in \u001b[0;36m_solve\u001b[1;34m(dependent, context, cache, history)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdependency\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdependencies\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m                 value, cache, history = _solve(dependency, context=context,\n\u001b[1;32m--> 229\u001b[1;33m                                                cache=cache, history=history)\n\u001b[0m\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/halfak/env/3.4/lib/python3.4/site-packages/revscoring-1.0.0rc2-py3.4.egg/revscoring/dependencies/functions.py\u001b[0m in \u001b[0;36m_solve\u001b[1;34m(dependent, context, cache, history)\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[1;31m# Generate value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdependent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mDependencyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/halfak/env/3.4/lib/python3.4/site-packages/revscoring-1.0.0rc2-py3.4.egg/revscoring/dependencies/dependent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m                      .format(self, self.calls))\n\u001b[0;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalls\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/halfak/env/3.4/lib/python3.4/site-packages/revscoring-1.0.0rc2-py3.4.egg/revscoring/features/wikitext/datasources/edit.py\u001b[0m in \u001b[0;36m_process_operations\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_process_operations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m     \u001b[0moperations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mop\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mop\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msegment_matcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m     logger.debug(\"diff() of {0} and {1} tokens took {2} seconds.\"\n\u001b[0;32m    280\u001b[0m                  .format(len(a), len(b), time.time() - start))\n",
      "\u001b[1;32m/home/halfak/env/3.4/lib/python3.4/site-packages/deltas-0.3.9-py3.4.egg/deltas/algorithms/segment_matcher.py\u001b[0m in \u001b[0;36mdiff\u001b[1;34m(a, b, segmenter)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[0mb_segments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msegmenter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msegment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdiff_segments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma_segments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_segments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/halfak/env/3.4/lib/python3.4/site-packages/deltas-0.3.9-py3.4.egg/deltas/algorithms/segment_matcher.py\u001b[0m in \u001b[0;36mdiff_segments\u001b[1;34m(a_segments, b_segments)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;31m# Match and re-sequence unmatched tokens\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     a_segment_tokens, b_segment_tokens = _cluster_matching_segments(a_segments,\n\u001b[1;32m---> 88\u001b[1;33m                                                                     b_segments)\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;31m# Perform a simple LCS over unmatched tokens and clusters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/halfak/env/3.4/lib/python3.4/site-packages/deltas-0.3.9-py3.4.egg/deltas/algorithms/segment_matcher.py\u001b[0m in \u001b[0;36m_cluster_matching_segments\u001b[1;34m(a_segments, b_segments)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[1;31m# Find and cluster matching content in 'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m     \u001b[0mb_segment_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_match_segments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma_segment_map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_segments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[1;31m# Expand unmatched segments from 'a'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/halfak/env/3.4/lib/python3.4/site-packages/deltas-0.3.9-py3.4.egg/deltas/algorithms/segment_matcher.py\u001b[0m in \u001b[0;36m_match_segments\u001b[1;34m(a_segment_map, b_segments)\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubsegment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSegment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubsegment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMatchableSegment\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m                \u001b[0msubsegment\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ma_segment_map\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m                 \u001b[0mmatched_segments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma_segment_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msubsegment\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Get matches\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Now for the whole set!\n",
    "training_features_reverted = []\n",
    "for rev_id, reverted in train_set:\n",
    "    try:\n",
    "        feature_values = list(api_extractor.extract(rev_id, features))\n",
    "    except RuntimeError as e:\n",
    "        sys.stderr.write(str(e))\n",
    "        continue\n",
    "    \n",
    "    sys.stderr.write(\".\")\n",
    "    training_features_reverted.append((rev_id, feature_values, reverted))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eeek!  Again this takes too long, so again, I uploaded a dataset with features already extracted @ ../datasets/demo/enwiki.features_reverted.training.20k_2015.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14660"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from revscoring.utilities.util import read_observations\n",
    "training_features_reverted_f = !cut ../datasets/demo/enwiki.features_reverted.training.20k_2015.tsv -f2-\n",
    "training_features_reverted = list(read_observations(training_features_reverted_f, features, lambda v: v==\"True\"))\n",
    "len(training_features_reverted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool.  Now that we have a set of features extracted for our training set, it's time to train a model.  `revscoring` provides a set of different classifier algorithms.  From past experience, I know a [gradient boosting](https://en.wikipedia.org/wiki/Gradient_boosting) classifier works well, so we'll use that.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seconds_elapsed': 10.442254543304443}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from revscoring.scorer_models import GradientBoosting\n",
    "is_reverted = GradientBoosting(features, version=\"live demo!\", \n",
    "                               learning_rate=0.01, max_features=\"log2\", \n",
    "                               n_estimators=700, max_depth=5,\n",
    "                               balanced_sample_weight=True, scale=True, center=True)\n",
    "\n",
    "is_reverted.train(training_features_reverted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a trained model that we can play around with.  Let's try a few edits from our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True 699665317 {'prediction': True, 'probability': {False: 0.3653827159786929, True: 0.6346172840213071}}\n",
      "True 683832871 {'prediction': False, 'probability': {False: 0.5427601696020695, True: 0.4572398303979305}}\n",
      "True 653913156 {'prediction': False, 'probability': {False: 0.8731074978367457, True: 0.1268925021632543}}\n",
      "True 654545786 {'prediction': False, 'probability': {False: 0.688150988890976, True: 0.31184901110902397}}\n",
      "True 670608733 {'prediction': False, 'probability': {False: 0.6281418079815413, True: 0.37185819201845866}}\n",
      "True 689399141 {'prediction': False, 'probability': {False: 0.6031169436522997, True: 0.39688305634770027}}\n",
      "True 662365029 {'prediction': True, 'probability': {False: 0.10219941693145007, True: 0.8978005830685499}}\n",
      "True 656782076 {'prediction': True, 'probability': {False: 0.3093742221434129, True: 0.6906257778565871}}\n",
      "True 698954388 {'prediction': True, 'probability': {False: 0.3584112509135534, True: 0.6415887490864466}}\n",
      "True 645603577 {'prediction': False, 'probability': {False: 0.5185836233318435, True: 0.48141637666815645}}\n",
      "False 687073859 {'prediction': False, 'probability': {False: 0.5949492028047447, True: 0.40505079719525533}}\n",
      "False 665341163 {'prediction': False, 'probability': {False: 0.6218051173559166, True: 0.3781948826440834}}\n",
      "False 654524549 {'prediction': False, 'probability': {False: 0.7789811638216773, True: 0.22101883617832274}}\n",
      "False 682425664 {'prediction': False, 'probability': {False: 0.6783433307602882, True: 0.32165666923971176}}\n",
      "False 674780271 {'prediction': False, 'probability': {False: 0.5924268859455573, True: 0.40757311405444274}}\n",
      "False 684793059 {'prediction': False, 'probability': {False: 0.7753421344367373, True: 0.2246578655632627}}\n",
      "False 655583788 {'prediction': False, 'probability': {False: 0.6292193497624562, True: 0.3707806502375438}}\n",
      "False 700003789 {'prediction': False, 'probability': {False: 0.5042809107794851, True: 0.4957190892205149}}\n",
      "False 659306547 {'prediction': False, 'probability': {False: 0.7005411948125162, True: 0.29945880518748375}}\n",
      "False 662149200 {'prediction': False, 'probability': {False: 0.6636912024177389, True: 0.33630879758226107}}\n"
     ]
    }
   ],
   "source": [
    "reverted_obs = [rev_id for rev_id, reverted in test_set if reverted]\n",
    "non_reverted_obs = [rev_id for rev_id, reverted in test_set if not reverted]\n",
    "\n",
    "for rev_id in reverted_obs[:10]:\n",
    "    feature_values = list(api_extractor.extract(rev_id, features))\n",
    "    score = is_reverted.score(feature_values)\n",
    "    print(True, rev_id, score)\n",
    "\n",
    "for rev_id in non_reverted_obs[:10]:\n",
    "    feature_values = list(api_extractor.extract(rev_id, features))\n",
    "    score = is_reverted.score(feature_values)\n",
    "    print(False, rev_id, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model\n",
    "So, the above analysis can help give us a sense for whether the model is working or not, but it's hard to standardize between models.  So, we can apply some metrics that are specially crafted for machine learning models.  \n",
    "\n",
    "But first, I'll need to load the pre-generated feature values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4862"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_features_reverted_f = !cut ../datasets/demo/enwiki.features_reverted.testing.20k_2015.tsv -f2-\n",
    "testing_features_reverted = list(read_observations(testing_features_reverted_f, features, lambda v: v==\"True\"))\n",
    "len(testing_features_reverted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision) -- The proportion of correct predictions\n",
    "* [Precision](https://en.wikipedia.org/wiki/Precision_and_recall) -- The proportion of correct positive predictions\n",
    "* [Recall](https://en.wikipedia.org/wiki/Precision_and_recall) -- The proportion of positive examples detected\n",
    "* [Receiver operating characteristic](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) -- An information theoretic measure comparing the false-positive and true-positive rates across the prediction probability for a model. \n",
    "* Filter rate at 90% recall -- The proportion of observations that can be ignored while still catching 90% of \"reverted\" edits.  \n",
    "\n",
    "We'll use revscoring statistics to measure these against the test set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScikitLearnClassifier\n",
      " - type: GradientBoosting\n",
      " - params: max_leaf_nodes=null, max_features=\"log2\", balanced_sample_weight=true, warm_start=false, scale=true, min_samples_split=2, learning_rate=0.01, random_state=null, verbose=0, center=true, n_estimators=700, presort=\"auto\", init=null, loss=\"deviance\", min_weight_fraction_leaf=0.0, min_samples_leaf=1, max_depth=5, subsample=1.0\n",
      " - version: live demo!\n",
      " - trained: 2016-02-22T17:11:09.186836\n",
      "\n",
      "Accuracy: 0.809\n",
      "Precision: 0.119\n",
      "Recall: 0.387\n",
      "ROC-AUC: 0.674\n",
      "Filter rate @ 0.9 recall: threshold=0.337, filter_rate=0.195, recall=0.902\n"
     ]
    }
   ],
   "source": [
    "from revscoring.scorer_models.test_statistics import accuracy, precision, recall, roc, filter_rate_at_recall\n",
    "\n",
    "is_reverted.test(testing_features_reverted, \n",
    "                 test_statistics=[accuracy(), precision(), recall(), roc(), filter_rate_at_recall(0.90)])\n",
    "\n",
    "print(is_reverted.format_info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus round!  Let's listen to Wikipedia's vandalism!\n",
    "\n",
    "So we don't have the most powerful damage detection classifier, but then again, we're only including 6 features.  Usually we run with ~60 features and get to much higher levels of fitness.  *but* this model is still useful and it should help us detect the most aggregious vandalism in Wikipedia.  In order to listen to Wikipedia, we'll need to connect to [RCStream](https://wikitech.wikimedia.org/wiki/RCStream) -- the same live feed that powers [listen to Wikipedia](http://listen.hatnote.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:socketIO_client:stream.wikimedia.org:80/socket.io/1: [packet error] unhandled namespace path ()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please review 706374308 {'prediction': True, 'probability': {False: 0.4067633764284275, True: 0.5932366235715725}}\n",
      "Please review 706374313 {'prediction': True, 'probability': {False: 0.49926439971761394, True: 0.5007356002823861}}\n",
      "Please review 706374334 {'prediction': True, 'probability': {False: 0.49926439971761394, True: 0.5007356002823861}}\n",
      "Please review 706374338 {'prediction': True, 'probability': {False: 0.06753894769918001, True: 0.93246105230082}}\n",
      "Please review 706374341 {'prediction': True, 'probability': {False: 0.3759632050952484, True: 0.6240367949047516}}\n",
      "Please review 706374345 {'prediction': True, 'probability': {False: 0.49832034024378247, True: 0.5016796597562175}}\n",
      "Please review 706374347 {'prediction': True, 'probability': {False: 0.49913166722881364, True: 0.5008683327711864}}\n",
      "Please review 706374349 {'prediction': True, 'probability': {False: 0.4112152426682467, True: 0.5887847573317533}}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-b67d42f17088>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0msocketIO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWikiNamespace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'/rc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0msocketIO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/halfak/env/3.4/lib/python3.4/site-packages/socketIO_client/__init__.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, seconds, for_callbacks)\u001b[0m\n\u001b[0;32m    250\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/halfak/env/3.4/lib/python3.4/site-packages/socketIO_client/__init__.py\u001b[0m in \u001b[0;36m_process_events\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mpacket\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transport\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_packet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_packet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpacket\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mPacketError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWARNING\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'[packet error] %s'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/halfak/env/3.4/lib/python3.4/site-packages/socketIO_client/__init__.py\u001b[0m in \u001b[0;36m_process_packet\u001b[1;34m(self, packet)\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[0mnamespace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_namespace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[0mdelegate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_delegate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m         \u001b[0mdelegate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpacket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_find_event_callback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_stop_waiting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfor_callbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/halfak/env/3.4/lib/python3.4/site-packages/socketIO_client/__init__.py\u001b[0m in \u001b[0;36m_on_event\u001b[1;34m(self, packet, find_event_callback)\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpacket_id\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_to_send_ack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpacket_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m         \u001b[0mfind_event_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_on_ack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpacket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfind_event_callback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-77-b67d42f17088>\u001b[0m in \u001b[0;36mon_change\u001b[1;34m(self, change)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mrev_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchange\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'revision'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'new'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mfeature_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi_extractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrev_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_reverted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'prediction'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/halfak/env/3.4/lib/python3.4/site-packages/revscoring-1.0.0rc2-py3.4.egg/revscoring/dependencies/functions.py\u001b[0m in \u001b[0;36m_solve_many\u001b[1;34m(dependents, context, cache)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdependent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdependents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m         \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_solve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdependent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/halfak/env/3.4/lib/python3.4/site-packages/revscoring-1.0.0rc2-py3.4.egg/revscoring/dependencies/functions.py\u001b[0m in \u001b[0;36m_solve\u001b[1;34m(dependent, context, cache, history)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdependency\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdependencies\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m                 value, cache, history = _solve(dependency, context=context,\n\u001b[1;32m--> 229\u001b[1;33m                                                cache=cache, history=history)\n\u001b[0m\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/halfak/env/3.4/lib/python3.4/site-packages/revscoring-1.0.0rc2-py3.4.egg/revscoring/dependencies/functions.py\u001b[0m in \u001b[0;36m_solve\u001b[1;34m(dependent, context, cache, history)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdependency\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdependencies\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m                 value, cache, history = _solve(dependency, context=context,\n\u001b[1;32m--> 229\u001b[1;33m                                                cache=cache, history=history)\n\u001b[0m\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/halfak/env/3.4/lib/python3.4/site-packages/revscoring-1.0.0rc2-py3.4.egg/revscoring/dependencies/functions.py\u001b[0m in \u001b[0;36m_solve\u001b[1;34m(dependent, context, cache, history)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdependency\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdependencies\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m                 value, cache, history = _solve(dependency, context=context,\n\u001b[1;32m--> 229\u001b[1;33m                                                cache=cache, history=history)\n\u001b[0m\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/halfak/env/3.4/lib/python3.4/site-packages/revscoring-1.0.0rc2-py3.4.egg/revscoring/dependencies/functions.py\u001b[0m in \u001b[0;36m_solve\u001b[1;34m(dependent, context, cache, history)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdependency\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdependencies\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m                 value, cache, history = _solve(dependency, context=context,\n\u001b[1;32m--> 229\u001b[1;33m                                                cache=cache, history=history)\n\u001b[0m\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/halfak/env/3.4/lib/python3.4/site-packages/revscoring-1.0.0rc2-py3.4.egg/revscoring/dependencies/functions.py\u001b[0m in \u001b[0;36m_solve\u001b[1;34m(dependent, context, cache, history)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdependency\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdependencies\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m                 value, cache, history = _solve(dependency, context=context,\n\u001b[1;32m--> 229\u001b[1;33m                                                cache=cache, history=history)\n\u001b[0m\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/halfak/env/3.4/lib/python3.4/site-packages/revscoring-1.0.0rc2-py3.4.egg/revscoring/dependencies/functions.py\u001b[0m in \u001b[0;36m_solve\u001b[1;34m(dependent, context, cache, history)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdependency\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdependencies\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m                 value, cache, history = _solve(dependency, context=context,\n\u001b[1;32m--> 229\u001b[1;33m                                                cache=cache, history=history)\n\u001b[0m\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/halfak/env/3.4/lib/python3.4/site-packages/revscoring-1.0.0rc2-py3.4.egg/revscoring/dependencies/functions.py\u001b[0m in \u001b[0;36m_solve\u001b[1;34m(dependent, context, cache, history)\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[1;31m# Generate value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdependent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mDependencyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/halfak/env/3.4/lib/python3.4/site-packages/revscoring-1.0.0rc2-py3.4.egg/revscoring/dependencies/dependent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m                      .format(self, self.calls))\n\u001b[0;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalls\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/halfak/env/3.4/lib/python3.4/site-packages/revscoring-1.0.0rc2-py3.4.egg/revscoring/datasources/meta/filters.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mitems\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mitems\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/halfak/env/3.4/lib/python3.4/site-packages/revscoring-1.0.0rc2-py3.4.egg/revscoring/datasources/meta/filters.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mitems\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mitems\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/halfak/env/3.4/lib/python3.4/site-packages/revscoring-1.0.0rc2-py3.4.egg/revscoring/features/wikitext/datasources/tokenized.py\u001b[0m in \u001b[0;36mfilter\u001b[1;34m(self, token)\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import socketIO_client\n",
    "\n",
    "class WikiNamespace(socketIO_client.BaseNamespace):\n",
    "    def on_change(self, change):\n",
    "        if change['type'] not in ('new', 'edit'):\n",
    "            return\n",
    "        \n",
    "        rev_id = change['revision']['new']\n",
    "        feature_values = list(api_extractor.extract(rev_id, features))\n",
    "        score = is_reverted.score(feature_values)\n",
    "        if score['prediction']:\n",
    "            print(\"Please review\", rev_id, score)\n",
    "\n",
    "    def on_connect(self):\n",
    "        self.emit('subscribe', 'en.wikipedia.org')\n",
    "\n",
    "\n",
    "socketIO = socketIO_client.SocketIO('stream.wikimedia.org', 80)\n",
    "socketIO.define(WikiNamespace, '/rc')\n",
    "\n",
    "socketIO.wait(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
